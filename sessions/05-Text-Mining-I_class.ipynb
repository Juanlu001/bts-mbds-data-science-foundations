{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BTS](img/Logo-BTS.jpg)\n",
    "\n",
    "# Session 5: Text Mining (I)\n",
    "\n",
    "### Juan Luis Cano Rodr√≠guez <juan.cano@bts.tech> - Data Science Foundations (2018-10-19)\n",
    "\n",
    "Open this notebook in Google Colaboratory: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Juanlu001/bts-mbds-data-science-foundations/blob/master/sessions/05-Text-Mining-I.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /home/juanlu/.miniconda36/envs/bts36/lib/python3.6/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/juanlu/.miniconda36/envs/bts36/lib/python3.6/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /home/juanlu/.miniconda36/envs/bts36/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "![Pipeline](img/pipelines.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word and sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"This is a happy sentence by Michael O'Leary.\"\n",
    "doc = nlp(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is a happy sentence by Michael O'Leary."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "happy\n",
      "sentence\n",
      "by\n",
      "Michael\n",
      "O'Leary\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].is_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[-1].is_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some\n",
      "spaces  and\ttab characters\n"
     ]
    }
   ],
   "source": [
    "text2 = 'Some\\nspaces  and\\ttab characters'\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.is_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(text2)[1].is_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some\n",
      "\n",
      "\n",
      "spaces\n",
      " \n",
      "and\n",
      "\t\n",
      "tab\n",
      "characters\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(text2):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"In ancient Rome, some neighbors live in three adjacent houses. In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus. A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom. One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates). One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero. Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).\"\n",
    "doc = nlp(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ancient Rome, some neighbors live in three adjacent houses.\n",
      "In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus.\n",
      "A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom.\n",
      "One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates).\n",
      "One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero.\n",
      "Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neighbour'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"they are neighbours\")[-1].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In ancient Rome.com, some neighbors live in three adjacent houses. In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus. A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom. One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates). One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero. Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin)."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text3)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'lemma_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-bd2051921498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\"hello\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'lemma_'"
     ]
    }
   ],
   "source": [
    "\"hello\".lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x7f8c27177af8>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vocab['is']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].lower_ in STOP_WORDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.lower_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[7].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'in' in STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'others', 'along', 'am', 'everywhere', 'elsewhere', 'were', 'forty', 'for', 'go', 'when', 'herself', 'has', 'not', 'all', 'sometime', 'does', 'indeed', 'into', 'next', 'seems', 'whenever', 'where', 'nor', 'perhaps', 'could', 'many', 'on', 'else', 'through', 'whether', 'while', 'anyone', 'cannot', 'whereby', 'both', 'any', 'part', 'own', 'might', 'we', 'few', 'another', 'either', 'but', 'latterly', 'per', 'upon', 'your', 'hereafter', 'anyhow', 'his', 'off', 'us', 'no', 'each', 'call', 'front', 'how', 'hundred', 'him', 'during', 'give', 'formerly', 'someone', 'thus', 'will', 'myself', 'alone', 'she', 'they', 'least', 'twelve', 'yours', 'much', 'still', 'must', 'already', 'its', 'across', 'latter', 'within', 'besides', 'wherein', 'these', 'becomes', 'below', 'doing', 're', 'out', 'take', 'via', 'onto', 'very', 'except', 'in', 'a', 'seem', 'seemed', 'unless', 'by', 'do', 'anyway', 'nevertheless', 'up', 'get', 'otherwise', 'first', 'whatever', 'fifteen', 'should', 'those', 'third', 'none', 'almost', 'i', 'nobody', 'them', 'throughout', 'using', 'with', 'at', 'most', 'often', 'bottom', 'whence', 'sometimes', 'becoming', 'what', 'whither', 'he', 'even', 'other', 'put', 'made', 'ever', 'been', 'whereas', 'enough', 'hereby', 'why', 'over', 'together', 'is', 'everything', 'really', 'amount', 'regarding', 'whole', 'well', 'whereafter', 'never', 'since', 'among', 'so', 'back', 'as', 'fifty', 'such', 'somewhere', 'every', 'mine', 'our', 'four', 'various', 'say', 'thereupon', 'there', 'nowhere', 'ca', 'because', 'being', 'yourself', 'was', 'can', 'of', 'one', 'only', 'seeming', 'somehow', 'thence', 'toward', 'again', 'afterwards', 'before', 'everyone', 'former', 'around', 'neither', 'more', 'six', 'yourselves', 'mostly', 'keep', 'eleven', 'me', 'three', 'used', 'full', 'be', 'side', 'had', 'it', 'moreover', 'some', 'yet', 'against', 'anywhere', 'between', 'sixty', 'down', 'five', 'from', 'herein', 'hereupon', 'move', 'therein', 'whose', 'would', 'above', 'then', 'thereafter', 'last', 'you', 'anything', 'name', 'have', 'beside', 'empty', 'quite', 'always', 'under', 'rather', 'just', 'amongst', 'became', 'here', 'to', 'nothing', 'see', 'which', 'my', 'their', 'or', 'please', 'serious', 'the', 'top', 'make', 'towards', 'thru', 'also', 'beforehand', 'thereby', 'themselves', 'after', 'eight', 'nine', 'once', 'an', 'ours', 'meanwhile', 'may', 'this', 'until', 'whereupon', 'beyond', 'same', 'whoever', 'about', 'less', 'behind', 'noone', 'that', 'are', 'now', 'done', 'hence', 'hers', 'than', 'show', 'without', 'due', 'several', 'wherever', 'something', 'whom', 'ourselves', 'himself', 'if', 'too', 'her', 'namely', 'twenty', 'further', 'two', 'who', 'did', 'and', 'however', 'therefore', 'although', 'ten', 'though', 'itself', 'become'}\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'ancient',\n",
       " 'rome.com',\n",
       " 'some',\n",
       " 'neighbor',\n",
       " 'live',\n",
       " 'in',\n",
       " 'three',\n",
       " 'adjacent',\n",
       " 'house',\n",
       " 'in',\n",
       " 'the',\n",
       " 'center',\n",
       " 'be',\n",
       " 'the',\n",
       " 'house',\n",
       " 'of',\n",
       " 'senex',\n",
       " 'who',\n",
       " 'live',\n",
       " 'there',\n",
       " 'with',\n",
       " 'wife',\n",
       " 'domina',\n",
       " 'son',\n",
       " 'hero',\n",
       " 'and',\n",
       " 'several',\n",
       " 'slave',\n",
       " 'include',\n",
       " 'head',\n",
       " 'slave',\n",
       " 'hysterium',\n",
       " 'and',\n",
       " 'the',\n",
       " 'musical',\n",
       " \"'s\",\n",
       " 'main',\n",
       " 'character',\n",
       " 'pseudolus',\n",
       " 'a',\n",
       " 'slave',\n",
       " 'belong',\n",
       " 'to',\n",
       " 'hero',\n",
       " 'pseudolus',\n",
       " 'wish',\n",
       " 'to',\n",
       " 'buy',\n",
       " 'win',\n",
       " 'or',\n",
       " 'steal',\n",
       " '-PRON-',\n",
       " 'freedom',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'neighbor',\n",
       " 'house',\n",
       " 'be',\n",
       " 'own',\n",
       " 'by',\n",
       " 'marcus',\n",
       " 'lycus',\n",
       " 'who',\n",
       " 'be',\n",
       " 'a',\n",
       " 'buyer',\n",
       " 'and',\n",
       " 'seller',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'woman',\n",
       " 'the',\n",
       " 'other',\n",
       " 'belong',\n",
       " 'to',\n",
       " 'the',\n",
       " 'ancient',\n",
       " 'erronius',\n",
       " 'who',\n",
       " 'be',\n",
       " 'abroad',\n",
       " 'search',\n",
       " 'for',\n",
       " '-PRON-',\n",
       " 'long',\n",
       " 'lose',\n",
       " 'child',\n",
       " 'steal',\n",
       " 'in',\n",
       " 'infancy',\n",
       " 'by',\n",
       " 'pirate',\n",
       " 'one',\n",
       " 'day',\n",
       " 'senex',\n",
       " 'and',\n",
       " 'domina',\n",
       " 'go',\n",
       " 'on',\n",
       " 'a',\n",
       " 'trip',\n",
       " 'and',\n",
       " 'leave',\n",
       " 'pseudolus',\n",
       " 'in',\n",
       " 'charge',\n",
       " 'of',\n",
       " 'hero',\n",
       " 'hero',\n",
       " 'confide',\n",
       " 'in',\n",
       " 'pseudolus',\n",
       " 'that',\n",
       " '-PRON-',\n",
       " 'be',\n",
       " 'in',\n",
       " 'love',\n",
       " 'with',\n",
       " 'the',\n",
       " 'lovely',\n",
       " 'philia',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'courtesan',\n",
       " 'in',\n",
       " 'the',\n",
       " 'house',\n",
       " 'of',\n",
       " 'lycus',\n",
       " 'albeit',\n",
       " 'still',\n",
       " 'a',\n",
       " 'virgin']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.lemma_ for token in doc if not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[15].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neighbor'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[5].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-speech tagging\n",
    "\n",
    "All tags recognized by spaCy are listed at https://spacy.io/api/annotation#pos-tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is a happy sentence by Michael O'Leary."
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text1)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This DET\n",
      "is VERB\n",
      "a DET\n",
      "happy ADJ\n",
      "sentence NOUN\n",
      "by ADP\n",
      "Michael PROPN\n",
      "O'Leary PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1100\" height=\"312.0\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">¬°</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Bienvenidos</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">al</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">curso</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Python!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,179.0 L762,167.0 778,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp_es = spacy.load(\"es\")\n",
    "displacy.render(nlp_es(\"¬°Bienvenidos al curso de Python!\"), style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1450\" height=\"399.5\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">happy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">sentence</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">by</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Michael</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">O'Leary.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,266.5 L758.0,254.5 742.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Information table\n",
    "\n",
    "Display a table with all the tokens of `text1` and the columns `[\"Text\", \"Lemma\", \"Coarse POS (pos)\", \"Fine POS (tag)\", \"Syntactic dependency\", \"Shape\", \"Alphanumeric\", \"Stop\"]`. Look in https://spacy.io/api/token#attributes for hints. Something like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Text</th>\n",
    "      <th>Lemma</th>\n",
    "      <th>Coarse POS (pos)</th>\n",
    "      <th>Fine POS (tag)</th>\n",
    "      <th>Syntactic dependency</th>\n",
    "      <th>Shape</th>\n",
    "      <th>Alphanumeric</th>\n",
    "      <th>Stop</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>This</td>\n",
    "      <td>this</td>\n",
    "      <td>DET</td>\n",
    "      <td>DT</td>\n",
    "      <td>nsubj</td>\n",
    "      <td>Xxxx</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>is</td>\n",
    "      <td>be</td>\n",
    "      <td>VERB</td>\n",
    "      <td>VBZ</td>\n",
    "      <td>ROOT</td>\n",
    "      <td>xx</td>\n",
    "      <td>True</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>...</th>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Coarse POS (pos)</th>\n",
       "      <th>Fine POS (tag)</th>\n",
       "      <th>Syntactic dependency</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Alphanumeric</th>\n",
       "      <th>Stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Text, Lemma, Coarse POS (pos), Fine POS (tag), Syntactic dependency, Shape, Alphanumeric, Stop]\n",
       "Index: []"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(columns=[\"Text\", \"Lemma\", \"Coarse POS (pos)\", \"Fine POS (tag)\", \"Syntactic dependency\", \"Shape\", \"Alphanumeric\", \"Stop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Coarse POS (pos)</th>\n",
       "      <th>Fine POS (tag)</th>\n",
       "      <th>Syntactic dependency</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Alphanumeric</th>\n",
       "      <th>Stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>attr</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Michael</td>\n",
       "      <td>michael</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O'Leary</td>\n",
       "      <td>o'leary</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>X'Xxxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Text     Lemma Coarse POS (pos) Fine POS (tag) Syntactic dependency  \\\n",
       "0      This      this              DET             DT                nsubj   \n",
       "1        is        be             VERB            VBZ                 ROOT   \n",
       "2         a         a              DET             DT                  det   \n",
       "3     happy     happy              ADJ             JJ                 amod   \n",
       "4  sentence  sentence             NOUN             NN                 attr   \n",
       "5        by        by              ADP             IN                 prep   \n",
       "6   Michael   michael            PROPN            NNP             compound   \n",
       "7   O'Leary   o'leary            PROPN            NNP                 pobj   \n",
       "8         .         .            PUNCT              .                punct   \n",
       "\n",
       "     Shape  Alphanumeric   Stop  \n",
       "0     Xxxx          True  False  \n",
       "1       xx          True   True  \n",
       "2        x          True   True  \n",
       "3     xxxx          True  False  \n",
       "4     xxxx          True  False  \n",
       "5       xx          True   True  \n",
       "6    Xxxxx          True  False  \n",
       "7  X'Xxxxx         False  False  \n",
       "8        .         False  False  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text1)\n",
    "\n",
    "rows = []\n",
    "for token in doc:\n",
    "    rows.append((token.text, token.lemma_, token.pos_, token.tag_,\n",
    "                 token.dep_, token.shape_, token.is_alpha, token.is_stop))\n",
    "\n",
    "pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"Text\", \"Lemma\", \"Coarse POS (pos)\", \"Fine POS (tag)\", \"Syntactic dependency\", \"Shape\", \"Alphanumeric\", \"Stop\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Michael</td>\n",
       "      <td>michael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O'Leary</td>\n",
       "      <td>o'leary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Text     Lemma\n",
       "0      This      this\n",
       "1        is        be\n",
       "2         a         a\n",
       "3     happy     happy\n",
       "4  sentence  sentence\n",
       "5        by        by\n",
       "6   Michael   michael\n",
       "7   O'Leary   o'leary\n",
       "8         .         ."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text1)\n",
    "\n",
    "rows = defaultdict(list)\n",
    "\n",
    "for token in doc:\n",
    "    rows[\"Text\"].append(token.text)\n",
    "    rows[\"Lemma\"].append(token.lemma_)\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Coarse POS (pos)</th>\n",
       "      <th>Fine POS (tag)</th>\n",
       "      <th>Syntactic dependency</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Alphanumeric</th>\n",
       "      <th>Stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence</td>\n",
       "      <td>sentence</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>attr</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Michael</td>\n",
       "      <td>michael</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O'Leary</td>\n",
       "      <td>o'leary</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>X'Xxxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Text     Lemma Coarse POS (pos) Fine POS (tag) Syntactic dependency  \\\n",
       "0      This      this              DET             DT                nsubj   \n",
       "1        is        be             VERB            VBZ                 ROOT   \n",
       "2         a         a              DET             DT                  det   \n",
       "3     happy     happy              ADJ             JJ                 amod   \n",
       "4  sentence  sentence             NOUN             NN                 attr   \n",
       "5        by        by              ADP             IN                 prep   \n",
       "6   Michael   michael            PROPN            NNP             compound   \n",
       "7   O'Leary   o'leary            PROPN            NNP                 pobj   \n",
       "8         .         .            PUNCT              .                punct   \n",
       "\n",
       "     Shape  Alphanumeric   Stop  \n",
       "0     Xxxx          True  False  \n",
       "1       xx          True   True  \n",
       "2        x          True   True  \n",
       "3     xxxx          True  False  \n",
       "4     xxxx          True  False  \n",
       "5       xx          True   True  \n",
       "6    Xxxxx          True  False  \n",
       "7  X'Xxxxx         False  False  \n",
       "8        .         False  False  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"Text\", \"Lemma\", \"Coarse POS (pos)\", \"Fine POS (tag)\", \"Syntactic dependency\", \"Shape\", \"Alphanumeric\", \"Stop\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity recognition\n",
    "\n",
    "https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = u'Apple is looking at buying U.K. startup for 1 billion USD'\n",
    "doc = nlp(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "1 billion USD MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">In ancient \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Rome\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", some neighbors live in \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " adjacent houses. In the center is the house of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Senex\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", who lives there with wife \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Domina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", son \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", and several slaves, including head slave \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hysterium\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and the musical's main character Pseudolus. A slave belonging to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", Pseudolus wishes to buy, win, or steal his freedom. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    One\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the neighboring houses is owned by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Marcus Lycus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", who is a buyer and seller of beautiful women; the other belongs to the ancient \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Erronius\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", who is abroad searching for his long-lost children (stolen in infancy by pirates). \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    One\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " day, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Senex\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Domina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " go on a trip and leave Pseudolus in charge of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " confides in Pseudolus that he is in love with the lovely \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Philia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the courtesans in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the House of Lycus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (albeit still a virgin).</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc3 = nlp(text3)\n",
    "\n",
    "displacy.render(doc3, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabularies\n",
    "\n",
    "* `Vocab` objects contain a set of look-up tables that make common information available across documents.\n",
    "* Indexing the `Vocab` retrieves a `Lexeme`, which contains all the context-independent information about a word.\n",
    "\n",
    "![Vocabularies](img/vocab.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.vocab.Vocab at 0x7f8c2ae9f748>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x7f8c19c0d828>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3.vocab[\"Madrid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x7f8c19b9b558>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex = doc3.vocab[\"Rome\"]\n",
    "lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xxxx'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.shape_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Word frequencies\n",
    "\n",
    "1. Load the `esa_news_all.parquet` dataset (only first 100 rows) and display the 20 most frequent _lemmas_ that are not stopwords.\n",
    "2. Load the `holy_grail.txt` dataset and display the 5 most frequent proper nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1    \\nThe Atmosphere-Space Interactions Monitor, a...\n",
       "2    \\nThese images from ESAs Mars Express show a c...\n",
       "3    \\nNext time you eat a tomato or sweet pepper, ...\n",
       "4    \\nEvery so often, your smartphone or tablet re...\n",
       "5    \\nThe magnetic field is arguably one of the mo...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "esa = pd.read_parquet(\"/tmp/esa_news_all.parquet\").head(100)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('space', 325),\n",
       " ('esa', 312),\n",
       " ('satellite', 261),\n",
       " ('mission', 218),\n",
       " ('earth', 131),\n",
       " ('time', 121),\n",
       " ('year', 114),\n",
       " ('orbit', 114),\n",
       " ('mars', 108),\n",
       " ('km', 106),\n",
       " ('launch', 105),\n",
       " ('new', 101),\n",
       " ('system', 101),\n",
       " ('datum', 95),\n",
       " ('station', 91),\n",
       " ('atmosphere', 90),\n",
       " ('planet', 89),\n",
       " ('work', 87),\n",
       " ('say', 86),\n",
       " ('high', 82)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter()\n",
    "for row in esa:\n",
    "    doc = nlp(row)\n",
    "    lemmas = [\n",
    "        token.lemma_ for token in doc\n",
    "        if not token.is_punct and not token.is_space and token.lower_ not in STOP_WORDS\n",
    "    ]\n",
    "    counts.update(lemmas)\n",
    "\n",
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = esa.str.cat(sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\n",
    "    token.lemma_ for token in doc\n",
    "    if not token.is_punct and not token.is_space and token.lower_ not in STOP_WORDS\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('space', 325),\n",
       " ('esa', 313),\n",
       " ('satellite', 261),\n",
       " ('mission', 218),\n",
       " ('earth', 131),\n",
       " ('time', 121),\n",
       " ('year', 114),\n",
       " ('orbit', 114),\n",
       " ('mars', 108),\n",
       " ('km', 106),\n",
       " ('launch', 103),\n",
       " ('new', 101),\n",
       " ('system', 101),\n",
       " ('datum', 95),\n",
       " ('station', 91),\n",
       " ('atmosphere', 90),\n",
       " ('planet', 89),\n",
       " ('work', 87),\n",
       " ('say', 86),\n",
       " ('high', 82)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appers = {}\n",
    "\n",
    "for lemma in lemmas:\n",
    "    if lemma not in appers:\n",
    "        appers[lemma] = 1\n",
    "    else:\n",
    "        appers[lemma] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atmosphere',\n",
       " 'space',\n",
       " 'interactions',\n",
       " 'monitor',\n",
       " 'know',\n",
       " 'space',\n",
       " 'storm',\n",
       " 'hunter',\n",
       " 'instal',\n",
       " 'today',\n",
       " 'outside',\n",
       " 'european',\n",
       " 'space',\n",
       " 'laboratory',\n",
       " 'columbus',\n",
       " 'operator',\n",
       " 'canada',\n",
       " 'command',\n",
       " 'international',\n",
       " 'space',\n",
       " 'stations',\n",
       " '16-m',\n",
       " 'long',\n",
       " 'robotic',\n",
       " 'arm',\n",
       " '314-kg',\n",
       " 'facility',\n",
       " 'dragon',\n",
       " 'spacecraft',\n",
       " 'cargo',\n",
       " 'hold',\n",
       " 'place',\n",
       " 'operation',\n",
       " 'columbus',\n",
       " 'point',\n",
       " 'straight',\n",
       " 'earth',\n",
       " 'storm',\n",
       " 'hunter',\n",
       " 'observe',\n",
       " 'lightning',\n",
       " 'powerful',\n",
       " 'electrical',\n",
       " 'burst',\n",
       " 'atmosphere',\n",
       " 'occur',\n",
       " 'thunderstorm',\n",
       " 'call',\n",
       " 'transient',\n",
       " 'luminous',\n",
       " 'event',\n",
       " 'inner',\n",
       " 'working',\n",
       " 'magnificent',\n",
       " 'force',\n",
       " 'nature',\n",
       " 'unknown',\n",
       " 'international',\n",
       " 'space',\n",
       " 'station',\n",
       " 'offer',\n",
       " 'great',\n",
       " 'vantage',\n",
       " 'point',\n",
       " 'gather',\n",
       " 'information',\n",
       " 'event',\n",
       " 'circle',\n",
       " '400',\n",
       " 'km',\n",
       " 'earth',\n",
       " 'cover',\n",
       " 'area',\n",
       " 'thunderstorm',\n",
       " 'appear',\n",
       " 'get',\n",
       " 'datum',\n",
       " 'check',\n",
       " 'communication',\n",
       " 'channel',\n",
       " 'storm',\n",
       " 'hunter',\n",
       " 'send',\n",
       " 'datum',\n",
       " 'international',\n",
       " 'space',\n",
       " 'station',\n",
       " 'network',\n",
       " 'beam',\n",
       " 'communication',\n",
       " 'satellite',\n",
       " 'ground',\n",
       " 'station',\n",
       " 'white',\n",
       " 'sands',\n",
       " 'usa',\n",
       " 'space',\n",
       " 'station',\n",
       " 'mission',\n",
       " 'control']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: n-grams\n",
    "\n",
    "n-grams are sequences of n words that appear together.\n",
    "\n",
    "1. Load the `imdb.tsv` dataset and create a list of tokens that are not stopwords or uppercase (to remove the proper nouns).\n",
    "2. Compute a list of bigrams (2-grams) from this list. (Hint below)\n",
    "3. Write a function to produce the list of n-grams of any given text, where `n` is a parameter.\n",
    "4. Display the 10 most frequent 3-grams of `imdb.tsv` (you can reuse part of Exercise 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(doc, n): \n",
    "    doc = [word for word in doc \n",
    "           if word.is_alpha # Get rid of punctuation\n",
    "           if not word.string.isupper()] # Get rid of all-caps speaker headings\n",
    "    return list(zip(*[doc[i:] for i in range(n)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'b', 'c', 'd', 'e', 'f', 'g'], ['b', 'c', 'd', 'e', 'f', 'g']]\n"
     ]
    }
   ],
   "source": [
    "ww = [\"a\", \"b\" ,\"c\", \"d\", \"e\", \"f\", \"g\"]\n",
    "print([ww[ii:] for ii in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(right, arm, off),\n",
       " (dancing, We, knights),\n",
       " (the, mightiest, tree),\n",
       " (my, name, do),\n",
       " (By, what, name),\n",
       " (no, such, thing),\n",
       " (one, you, see),\n",
       " (no, Nu, No),\n",
       " (design, shrubberies, are),\n",
       " (Burn, her, Burn),\n",
       " (can, you, not),\n",
       " (Hah, clunk, Come),\n",
       " (chanting, Pie, Iesu),\n",
       " (What, are, they),\n",
       " (leap, out, of),\n",
       " (Quick, What, Quick),\n",
       " (Now, he, said),\n",
       " (again, That, what),\n",
       " (problem, What, is),\n",
       " (You, were, in),\n",
       " (What, a, strange),\n",
       " (Ah, well, actually),\n",
       " (and, chorus, scenes),\n",
       " (all, the, decision),\n",
       " (you, mean, An),\n",
       " (up, Look, squeak),\n",
       " (there, a, Saint),\n",
       " (You, not, doing),\n",
       " (into, a, pulp),\n",
       " (We, are, all),\n",
       " (spanking, There, is),\n",
       " (What, does, it),\n",
       " (escape, Excuse, me),\n",
       " (up, And, sneaking),\n",
       " (seems, to, be),\n",
       " (yes, Saint, Iiiives),\n",
       " (today, to, witness),\n",
       " (stand, it, people),\n",
       " (the, rabbit, taking),\n",
       " (Princess, and, the),\n",
       " (doctors, immediately, No),\n",
       " (Anthrax, Yes, Oh),\n",
       " (death, awaits, you),\n",
       " (Arthur, and, Bedevere),\n",
       " (third, number, be),\n",
       " (pause, You, have),\n",
       " (am, enjoying, this),\n",
       " (is, Oh, bloody),\n",
       " (this, place, with),\n",
       " (requiem, Pie, Iesu),\n",
       " (mandate, from, the),\n",
       " (for, now, lads),\n",
       " (He, going, to),\n",
       " (a, very, good),\n",
       " (Make, sure, the),\n",
       " (has, seen, the),\n",
       " (Then, you, shall),\n",
       " (punishment, for, setting),\n",
       " (Yeaah, Did, you),\n",
       " (gone, illegitimate, faced),\n",
       " (Doctor, Piglet, Doctor),\n",
       " (taunting, We, shall),\n",
       " (good, idea, Behold),\n",
       " (a, shrubbery, my),\n",
       " (much, Not, at),\n",
       " (that, Thou, hast),\n",
       " (really, most, awfully),\n",
       " (Burn, the, witch),\n",
       " (Hello, Hello, Hello),\n",
       " (of, Ewing, accompanied),\n",
       " (will, make, a),\n",
       " (We, thank, Thee),\n",
       " (that, in, crash),\n",
       " (Knights, Knights, Who),\n",
       " (twong, Well, taken),\n",
       " (it, off, Yes),\n",
       " (clap, clap, clap),\n",
       " (he, not, dead),\n",
       " (shalt, be, the),\n",
       " (we, tough, and),\n",
       " (with, that, Please),\n",
       " (to, relax, Are),\n",
       " (a, a, a),\n",
       " (line, between, them),\n",
       " (through, and, made),\n",
       " (the, supports, whop),\n",
       " (entrance, to, this),\n",
       " (And, if, you),\n",
       " (of, wherein, carved),\n",
       " (grail, shaped, beacon),\n",
       " (of, minutes, He),\n",
       " (not, have, died),\n",
       " (will, to, old),\n",
       " (week, Yes, But),\n",
       " (wicked, bad, naughty),\n",
       " (If, you, will),\n",
       " (climes, in, winter),\n",
       " (too, perilous, Look),\n",
       " (Get, back, Get),\n",
       " (he, would, bother),\n",
       " (the, legendary, Black),\n",
       " (clunk, Jesus, Christ),\n",
       " (do, singing, feel),\n",
       " (cop, Burn, her),\n",
       " (me, as, her),\n",
       " (your, leg, kick),\n",
       " (van, Get, a),\n",
       " (Saint, Ives, Oh),\n",
       " (apart, from, witches),\n",
       " (Pie, Iesu, domine),\n",
       " (thank, you, Oh),\n",
       " (object, to, is),\n",
       " (Be, quiet, But),\n",
       " (your, lord, and),\n",
       " (King, of, the),\n",
       " (the, strength, of),\n",
       " (Clear, off, Go),\n",
       " (not, my, liege),\n",
       " (must, give, us),\n",
       " (What, is, your),\n",
       " (We, have, the),\n",
       " (full, fifty, men),\n",
       " (has, got, a),\n",
       " (not, quite, dead),\n",
       " (questions, may, cross),\n",
       " (score, young, blondes),\n",
       " (You, are, a),\n",
       " (No, not, is),\n",
       " (Come, Come, You),\n",
       " (nose, The, nose),\n",
       " (of, the, previous),\n",
       " (assist, us, voluntarily),\n",
       " (is, King, Arthur),\n",
       " (performance, clop, clop),\n",
       " (Robin, So, each),\n",
       " (Shh, We, lost),\n",
       " (it, here, in),\n",
       " (An, African, or),\n",
       " (can, summon, up),\n",
       " (Gallahad, the, Pure),\n",
       " (Joseph, of, Arimathea),\n",
       " (all, right, to),\n",
       " (high, pitched, Get),\n",
       " (Anthrax, we, have),\n",
       " (angels, sing, Arthur),\n",
       " (that, Hurry, Sir),\n",
       " (migrate, Not, at),\n",
       " (we, tell, whether),\n",
       " (will, give, us),\n",
       " (for, my, idiom),\n",
       " (Lord, God, be),\n",
       " (in, here, and),\n",
       " (not, be, so),\n",
       " (basis, for, a),\n",
       " (his, body, burned),\n",
       " (wet, himself, at),\n",
       " (Til, Recently, Said),\n",
       " (me, in, my),\n",
       " (need, to, do),\n",
       " (his, tail, and),\n",
       " (not, to, enter),\n",
       " (but, dangerous, Sir),\n",
       " (some, farcical, aquatic),\n",
       " (clang, Aaaaaaaah, chops),\n",
       " (soon, to, follow),\n",
       " (relics, Brother, Maynard),\n",
       " (Ohh, Ohh, Burn),\n",
       " (Knight, will, you),\n",
       " (Right, One, two),\n",
       " (is, hidden, Tim),\n",
       " (outside, castle, Morning),\n",
       " (your, son, No),\n",
       " (and, get, him),\n",
       " (who, We, are),\n",
       " (strange, women, lying),\n",
       " (two, level, effect),\n",
       " (we, lose, Gawain),\n",
       " (to, which, God),\n",
       " (they, did, Aaaah),\n",
       " (were, walking, and),\n",
       " (must, return, here),\n",
       " (be, found, the),\n",
       " (right, Right, We),\n",
       " (You, must, spank),\n",
       " (her, Burn, her),\n",
       " (this, one, Come),\n",
       " (asking, Oh, Oooo),\n",
       " (Burn, her, Burn),\n",
       " (proved, yourself, worthy),\n",
       " (way, Dramatically, sir),\n",
       " (scratch, Your, arm),\n",
       " (bloody, hell, Ha),\n",
       " (the, fourth, one),\n",
       " (Three, sir, Three),\n",
       " (Right, clop, clop),\n",
       " (It, unhealthy, bet),\n",
       " (oral, sex, The),\n",
       " (again, And, there),\n",
       " (vicious, Chicken, of),\n",
       " (back, here, and),\n",
       " (herring, dramatic, chord),\n",
       " (ha, Heh, hee),\n",
       " (can, not, hear),\n",
       " (other, side, he),\n",
       " (feel, much, better),\n",
       " (Ohh, That, the),\n",
       " (you, Now, he),\n",
       " (allowed, to, enter),\n",
       " (of, the, Round),\n",
       " (little, bleeder, One),\n",
       " (a, very, brave),\n",
       " (miserable, they, so),\n",
       " (the, other, side),\n",
       " (north, east, that),\n",
       " (It, is, It),\n",
       " (we, have, but),\n",
       " (again, to, you),\n",
       " (it, Oh, come),\n",
       " (in, haste, Who),\n",
       " (it, Amen, Amen),\n",
       " (of, Death, The),\n",
       " (Oh, it, just),\n",
       " (like, that, It),\n",
       " (is, a, witch),\n",
       " (you, a, busy),\n",
       " (Brother, Maynard, carries),\n",
       " (your, every, every),\n",
       " (give, me, a),\n",
       " (Table, You, a),\n",
       " (testicles, already, Ha),\n",
       " (not, Ah, well),\n",
       " (direction, sons, of),\n",
       " (mumble, mumble, mumble),\n",
       " (do, good, lady),\n",
       " (but, you, ca),\n",
       " (shrubbery, you, must),\n",
       " (Come, You, may),\n",
       " (Right, Yeaaah, Yeaah),\n",
       " (previous, scenes, think),\n",
       " (hear, that, Did),\n",
       " (dona, eis, requiem),\n",
       " (a, swallow, needs),\n",
       " (of, Arimathea, He),\n",
       " (Get, on, with),\n",
       " (This, is, the),\n",
       " (not, is, Not),\n",
       " (bravely, taking, to),\n",
       " (Oh, great, Look),\n",
       " (then, proceed, to),\n",
       " (Ooh, King, Arthur),\n",
       " (Go, away, Go),\n",
       " (not, next, to),\n",
       " (a, duck, you),\n",
       " (of, many, a),\n",
       " (terrible, peril, Look),\n",
       " (saw, saw, saw),\n",
       " (small, problem, What),\n",
       " (to, come, with),\n",
       " (Uh, leap, out),\n",
       " (it, and, lived),\n",
       " (He, is, brave),\n",
       " (who, being, naughty),\n",
       " (the, big, one),\n",
       " (you, ai, heard),\n",
       " (name, of, God),\n",
       " (guards, Uh, Oh),\n",
       " (fooling, anyone, you),\n",
       " (to, be, a),\n",
       " (Oh, do, think),\n",
       " (and, Monsieur, Arthur),\n",
       " (filth, down, here),\n",
       " (Pie, Iesu, domine),\n",
       " (King, of, the),\n",
       " (to, be, any),\n",
       " (How, dare, you),\n",
       " (four, really, if),\n",
       " (woman, Erm, yes),\n",
       " (and, make, sure),\n",
       " (mumble, mumble, boom),\n",
       " (See, it, Oh),\n",
       " (He, knows, of),\n",
       " (of, whom, the),\n",
       " (he, seemed, about),\n",
       " (Hee, hee, heh),\n",
       " (must, answer, me),\n",
       " (And, uh, make),\n",
       " (the, keeper, of),\n",
       " (Oh, To, the),\n",
       " (witches, More, witches),\n",
       " (And, again, Over),\n",
       " (pull, it, off),\n",
       " (To, have, his),\n",
       " (had, personally, wet),\n",
       " (only, if, ye),\n",
       " (says, he, not),\n",
       " (eis, requiem, Wayy),\n",
       " (The, cartoon, peril),\n",
       " (to, the, north),\n",
       " (if, the, birds),\n",
       " (police, radio, Launcelot),\n",
       " (turns, to, act),\n",
       " (Just, you, Hic),\n",
       " (a, fair, cop),\n",
       " (her, Burn, her),\n",
       " (with, your, silly),\n",
       " (out, your, dead),\n",
       " (now, we, glad),\n",
       " (warm, and, soft),\n",
       " (to, push, the),\n",
       " (thud, thud, King),\n",
       " (Launcelot, police, radio),\n",
       " (Uh, he, already),\n",
       " (Maynard, Bring, up),\n",
       " (Table, My, liege),\n",
       " (rejoicing, Yay, Yay),\n",
       " (great, idea, Why),\n",
       " (there, Then, who),\n",
       " (one, small, problem),\n",
       " (dead, What, Nothing),\n",
       " (Patsy, None, shall),\n",
       " (carrying, a, coconut),\n",
       " (the, penalty, And),\n",
       " (ha, He, knows),\n",
       " (on, a, swamp),\n",
       " (uh, sort, of),\n",
       " (to, You, put),\n",
       " (so, cruel, that),\n",
       " (think, you, could),\n",
       " (has, He, scarper),\n",
       " (hee, hee, hee),\n",
       " (bit, uh, sort),\n",
       " (uuup, singing, He),\n",
       " (Court, of, Camelot),\n",
       " (afraid, What, is),\n",
       " (out, want, to),\n",
       " (Oh, let, me),\n",
       " (how, get, that),\n",
       " (to, follow, Sir),\n",
       " (squeak, squeak, squeak),\n",
       " (knees, bent, running),\n",
       " (chastity, Back, to),\n",
       " (charged, by, God),\n",
       " (a, mandate, from),\n",
       " (out, your, dead),\n",
       " (Oh, Ahh, Summer),\n",
       " (shrubbery, You, must),\n",
       " (under, considerable, economic),\n",
       " (the, swamp, So),\n",
       " (be, praised, King),\n",
       " (Arthur, King, who),\n",
       " (if, went, round),\n",
       " (We, shall, do),\n",
       " (Run, away, roar),\n",
       " (the, pond, What),\n",
       " (Table, The, wise),\n",
       " (liege, Good, Sir),\n",
       " (would, bother, to),\n",
       " (thing, you, tiny),\n",
       " (a, smashing, scene),\n",
       " (French, fellows, outwit),\n",
       " (sir, singing, He),\n",
       " (We, must, examine),\n",
       " (watery, tart, threw),\n",
       " (that, rabbit, got),\n",
       " (sir, Well, you),\n",
       " (you, a, king),\n",
       " (Good, luck, brave),\n",
       " (boom, There, Look),\n",
       " (Camelot, What, is),\n",
       " (master, Guy, de),\n",
       " (Look, What, does),\n",
       " (but, a, scratch),\n",
       " (some, watery, tart),\n",
       " (hand, electric, donkey),\n",
       " (friend, and, will),\n",
       " (knights, of, the),\n",
       " (mother, was, a),\n",
       " (am, Zoot, identical),\n",
       " (it, Yes, get),\n",
       " (going, to, cost),\n",
       " (nice, Spring, changed),\n",
       " (must, answer, me),\n",
       " (a, swallow, flight),\n",
       " (do, vote, for),\n",
       " (dogs, Go, and),\n",
       " (it, a, good),\n",
       " (of, weight, ratios),\n",
       " (Amen, Amen, Right),\n",
       " (Galahad, No, Look),\n",
       " (in, my, own),\n",
       " (Yes, Oh, not),\n",
       " (bint, had, lobbed),\n",
       " (with, it, Oh),\n",
       " (Round, Table, clop),\n",
       " (at, a, special),\n",
       " (Stop, it, Who),\n",
       " (You, are, the),\n",
       " (a, lady, can),\n",
       " (Oh, shut, up),\n",
       " (Excalibur, from, the),\n",
       " (fair, and, we),\n",
       " (so, we, looking),\n",
       " (Come, along, Everything),\n",
       " (other, side, he),\n",
       " (were, forced, to),\n",
       " (Oh, but, you),\n",
       " (pig, country, Is),\n",
       " (a, fatal, heart),\n",
       " (seek, the, Holy),\n",
       " (take, this, castle),\n",
       " (Chop, his, head),\n",
       " (Burn, Burn, her),\n",
       " (up, Oh, Come),\n",
       " (is, it, you),\n",
       " (died, And, want),\n",
       " (suffered, much, You),\n",
       " (of, the, rabbit),\n",
       " (built, a, second),\n",
       " (well, If, you),\n",
       " (He, do, you),\n",
       " (Hee, ha, ha),\n",
       " (the, Shrubber, arrange),\n",
       " (Get, on, with),\n",
       " (anyone, No, not),\n",
       " (under, the, dorsal),\n",
       " (Grail, Where, is),\n",
       " (want, his, only),\n",
       " (Look, squeak, Aaaugh),\n",
       " (Not, like, that),\n",
       " (were, an, autonomous),\n",
       " (it, in, and),\n",
       " (travellers, who, seek),\n",
       " (Launcelot, of, What),\n",
       " (awhile, Midget, Crapper),\n",
       " (English, k, nnnnniggets),\n",
       " (thine, enemies, to),\n",
       " (Aaaah, slash, kills),\n",
       " (Oh, wo, go),\n",
       " (my, court, at),\n",
       " (witch, bonk, witch),\n",
       " (Joseph, of, Arimathea),\n",
       " (and, the, bravest),\n",
       " (own, father, who),\n",
       " (Bors, Chop, his),\n",
       " (eats, That, it),\n",
       " (You, fell, out),\n",
       " (has, just, fallen),\n",
       " (quiet, But, by),\n",
       " (and, these, are),\n",
       " (Oh, she, is),\n",
       " (are, my, Knights),\n",
       " (bit, and, bit),\n",
       " (be, three, Four),\n",
       " (mortally, wounded, in),\n",
       " (stops, Aaagh, King),\n",
       " (think, all, right),\n",
       " (us, in, our),\n",
       " (could, say, Dennis),\n",
       " (sniff, Now, this),\n",
       " (uh, Ohh, Oh),\n",
       " (a, bed, and),\n",
       " (at, the, castle),\n",
       " (eis, requiem, bonk),\n",
       " (pound, pound, pound),\n",
       " (without, flint, or),\n",
       " (you, can, do),\n",
       " (and, giggle, giggle),\n",
       " (it, have, seen),\n",
       " (No, it, nothing),\n",
       " (domine, donaeis, requiem),\n",
       " (the, vicious, Chicken),\n",
       " (join, us, in),\n",
       " (act, as, a),\n",
       " (saying, was, an),\n",
       " (Knights, Who, Say),\n",
       " (What, You, got),\n",
       " (stand, aside, move),\n",
       " (music, stops, stab),\n",
       " (twang, splash, Heh),\n",
       " (of, Sir, Galahad),\n",
       " (bois, Quoi, Un),\n",
       " (It, is, the),\n",
       " (said, it, clop),\n",
       " (No, not, is),\n",
       " (got, us, all),\n",
       " (Aaagh, King, Arthur),\n",
       " (very, small, rocks),\n",
       " (questions, as, best),\n",
       " (squeak, squeak, squeak),\n",
       " (his, only, daughter),\n",
       " (more, no, less),\n",
       " (Robin, He, was),\n",
       " (haw, Ha, Ha),\n",
       " (Oh, no, you),\n",
       " (in, which, Arthur),\n",
       " (have, a, task),\n",
       " (Knights, of, Ni),\n",
       " (Castle, Anthrax, The),\n",
       " (Erm, yes, Oh),\n",
       " (is, why, am),\n",
       " (the, rabbit, uh),\n",
       " (least, ours, was),\n",
       " (is, eet, It),\n",
       " (with, you, No),\n",
       " (decided, that, they),\n",
       " (Then, shalt, thou),\n",
       " (This, is, Sir),\n",
       " (clop, Now, this),\n",
       " (stab, Aagh, Oh),\n",
       " (Stop, saying, the),\n",
       " (Camelot, Uh, very),\n",
       " (Just, keep, him),\n",
       " (and, boil, your),\n",
       " (me, no, longer),\n",
       " (is, one, small),\n",
       " (a, a, a),\n",
       " (by, force, splat),\n",
       " (Yes, yes, you),\n",
       " (think, was, Yes),\n",
       " (Today, the, blood),\n",
       " (Oh, yeah, an),\n",
       " (He, going, to),\n",
       " (Yes, Oh, it),\n",
       " (an, African, swallow),\n",
       " (is, for, your),\n",
       " (vache, Quoi, Fetchez),\n",
       " (naughty, in, my),\n",
       " (not, doing, it),\n",
       " (boom, mumble, mumble),\n",
       " (shalt, thou, take),\n",
       " (you, can, And),\n",
       " (sorry, Sorry, Sorry),\n",
       " (again, warned, you),\n",
       " (opening, request, a),\n",
       " (all, hacked, and),\n",
       " (for, you, You),\n",
       " (more, than, reasonable),\n",
       " (Right, Hic, Right),\n",
       " (police, siren, Yes),\n",
       " (What, are, you),\n",
       " (you, think, she),\n",
       " (do, you, up),\n",
       " (Dramatically, singing, But),\n",
       " (of, the, rabbit),\n",
       " (Shrubberies, are, my),\n",
       " (Galahad, and, uh),\n",
       " (better, You, fell),\n",
       " (Burn, her, Burn),\n",
       " (No, No, No),\n",
       " (now, no, longer),\n",
       " (somebody, give, me),\n",
       " (enough, eh, Look),\n",
       " (life, must, seem),\n",
       " (three, Four, shalt),\n",
       " (to, the, Grail),\n",
       " (And, what, do),\n",
       " (underwear, We, are),\n",
       " (mangy, scots, git),\n",
       " (going, to, tell),\n",
       " (land, Are, you),\n",
       " (of, the, Holy),\n",
       " (King, Arthur, music),\n",
       " (thou, not, count),\n",
       " (e, does, leave),\n",
       " (of, God, and),\n",
       " (of, the, knights),\n",
       " (clop, You, fight),\n",
       " (king, Oh, king),\n",
       " (of, government, Supreme),\n",
       " (be, praised, Almighty),\n",
       " (happy, feel, happy),\n",
       " (quite, clear, No),\n",
       " (the, swamp, So),\n",
       " (daft, me, to),\n",
       " (a, strange, person),\n",
       " (Grail, Heh, hee),\n",
       " (Robin, ran, away),\n",
       " (off, Go, on),\n",
       " (want, to, cut),\n",
       " (saved, at, the),\n",
       " (he, a, guard),\n",
       " (Follow, only, if),\n",
       " (Gable, It, a),\n",
       " (Look, on, Clear),\n",
       " (scribble, fold, fold),\n",
       " (quack, quack, We),\n",
       " (he, doing, here),\n",
       " (Come, on, No),\n",
       " (our, beacon, which),\n",
       " (you, go, mayhem),\n",
       " (not, biscuits, All),\n",
       " (no, sweet, Concorde),\n",
       " (married, to, a),\n",
       " (another, shrubbery, Ni),\n",
       " (sure, he, does),\n",
       " (Arthur, and, Sir),\n",
       " (a, Knight, of),\n",
       " (Would, it, help),\n",
       " (In, God, name),\n",
       " (me, invincible, You),\n",
       " (Sir, Robin, brave),\n",
       " (art, Try, to),\n",
       " (what, it, says),\n",
       " (to, my, commands),\n",
       " (out, uh, Launcelot),\n",
       " (Packing, it, in),\n",
       " (is, there, There),\n",
       " (Bravely, bold, Sir),\n",
       " (of, pussy, jokes),\n",
       " (arrows, at, the),\n",
       " (peril, No, he),\n",
       " (is, a, witch),\n",
       " (Father, Well, let),\n",
       " (what, Well, ooh),\n",
       " (Death, which, leads),\n",
       " (it, if, we),\n",
       " (wedding, guests, in),\n",
       " (the, Holy, Grail),\n",
       " (killed, my, auntie),\n",
       " (least, ours, was),\n",
       " (committed, It, was),\n",
       " (Ha, ha, ha),\n",
       " (am, a, shrubber),\n",
       " (Rheged, boom, make),\n",
       " (Well, it, always),\n",
       " (castle, by, force),\n",
       " (naughty, evil, Zoot),\n",
       " (boom, Hello, Welcome),\n",
       " (class, into, it),\n",
       " (you, will, not),\n",
       " (castle, of, Camelot),\n",
       " (from, scene, twenty),\n",
       " (him, entering, the),\n",
       " (what, Ni, Ni),\n",
       " (does, it, work),\n",
       " (taunt, you, a),\n",
       " (get, lad, the),\n",
       " (in, Britain, but),\n",
       " (feel, sure, that),\n",
       " (him, feel, fine),\n",
       " (seek, the, finest),\n",
       " (What, is, your),\n",
       " (uh, by, surprise),\n",
       " (her, He, getting),\n",
       " (One, rabbit, stew),\n",
       " (take, him, like),\n",
       " (Our, quest, is),\n",
       " (witch, Uh, but),\n",
       " (quiet, Order, eh),\n",
       " (what, name, are),\n",
       " (no, man, has),\n",
       " (is, mine, Oh),\n",
       " (Brave, brave, Concorde),\n",
       " (about, swallows, Well),\n",
       " (Where, could, we),\n",
       " (Yes, Brave, Sir),\n",
       " (afraid, when, in),\n",
       " (left, Yes, have),\n",
       " (In, twenty, minutes),\n",
       " (Three, sir, Three),\n",
       " (Where, you, get),\n",
       " (she, weighs, the),\n",
       " (the, union, of),\n",
       " (her, Burn, her),\n",
       " (it, sorry, this),\n",
       " (Bridge, of, Death),\n",
       " (is, a, temperate),\n",
       " (boom, What, are),\n",
       " (shall, not, stop),\n",
       " (enough, music, for),\n",
       " (life, in, Camelot),\n",
       " (this, Augh, we),\n",
       " (mumble, boom, mumble),\n",
       " (spoken, in, scene),\n",
       " (it, only, because),\n",
       " (your, dead, clang),\n",
       " (Sir, Launcelot, of),\n",
       " (wield, supreme, executive),\n",
       " (we, able, We),\n",
       " (husk, It, not),\n",
       " (What, is, your),\n",
       " (Burn, the, witch),\n",
       " (the, bones, Go),\n",
       " (one, of, them),\n",
       " (To, whoever, finds),\n",
       " (note, have, been),\n",
       " (Fine, Um, do),\n",
       " (Herbert, has, just),\n",
       " (of, many, men),\n",
       " (sun, or, the),\n",
       " (against, regulations, do),\n",
       " (No, no, Aauuuuugh),\n",
       " (the, Bridge, of),\n",
       " (the, curtains, lad),\n",
       " (no, You, see),\n",
       " (sire, Then, we),\n",
       " (then, French, Why),\n",
       " (Come, on, With),\n",
       " (Camelot, and, join),\n",
       " (Good, Sir, Knight),\n",
       " (Assyria, do, know),\n",
       " (chanting, Pie, Iesu),\n",
       " (the, Knights, Who),\n",
       " (tear, them, apart),\n",
       " (us, How, you),\n",
       " (a, two, thirds),\n",
       " (find, the, Holy),\n",
       " (in, water, Bread),\n",
       " (Robinson, They, lost),\n",
       " (a, coconut, on),\n",
       " (then, dunno, Must),\n",
       " (an, anarcho, syndicalist),\n",
       " (thou, then, proceed),\n",
       " (and, anchovies, and),\n",
       " (Now, this, is),\n",
       " (Well, you, shall),\n",
       " (made, into, one),\n",
       " (Yup, That, it),\n",
       " (Bring, out, your),\n",
       " (my, private, parts),\n",
       " (and, make, castanets),\n",
       " (a, cave, which),\n",
       " (enchanter, By, what),\n",
       " (saw, saw, saw),\n",
       " (Winter, gave, Spring),\n",
       " (if, he, wants),\n",
       " (but, other, illustrious),\n",
       " (who, arrange, and),\n",
       " (idea, Behold, angels),\n",
       " (The, dead, Prince),\n",
       " (the, real, Grail),\n",
       " (master, that, we),\n",
       " (course, not, You),\n",
       " (sacred, castle, No),\n",
       " (you, welcome, to),\n",
       " (castle, No, one),\n",
       " (Hello, Hello, Hello),\n",
       " (And, this, enchanter),\n",
       " (me, Sir, Bedevere),\n",
       " (will, Please, please),\n",
       " (Put, this, man),\n",
       " (necessary, We, must),\n",
       " (hee, ha, ha),\n",
       " (uh, just, just),\n",
       " (van, Clear, off),\n",
       " (case, shall, have),\n",
       " (bonk, Pie, Iesu),\n",
       " (her, Burn, Burn),\n",
       " (Grail, singing, He),\n",
       " (out, did, you),\n",
       " (taunting, took, him),\n",
       " (you, gon, na),\n",
       " (about, his, great),\n",
       " (Sir, Robin, His),\n",
       " (The, Britons, Who),\n",
       " (grail, Yes, think),\n",
       " (twenty, four, Beyond),\n",
       " (Pie, Iesu, domine),\n",
       " (search, to, find),\n",
       " (burn, her, Burn),\n",
       " (No, no, Until),\n",
       " (now, we, see),\n",
       " (tail, and, fled),\n",
       " (clop, clop, Halt),\n",
       " (Holy, Grail, Where),\n",
       " (Ninepence, clang, Bring),\n",
       " (very, living, rock),\n",
       " (fight, is, mine),\n",
       " (upon, this, land),\n",
       " (music, And, no),\n",
       " (sorry, about, the),\n",
       " (Oh, am, enjoying),\n",
       " (In, the, frozen),\n",
       " (Get, back, All),\n",
       " (Bring, out, your),\n",
       " (Blue, No, auuuuuuuugh),\n",
       " (haw, Haw, Haw),\n",
       " (your, lord, We),\n",
       " (no, man, has),\n",
       " (Tale, of, Sir),\n",
       " (her, into, the),\n",
       " (there, Ah, What),\n",
       " (a, What, are),\n",
       " (and, jam, and),\n",
       " (totally, unarmed, Who),\n",
       " (be, the, trouble),\n",
       " (make, them, an),\n",
       " (chord, Not, another),\n",
       " (may, lie, here),\n",
       " (the, approaching, any),\n",
       " (it, He, said),\n",
       " (blanket, We, have),\n",
       " (can, he, leave),\n",
       " (thwonk, Message, for),\n",
       " (ha, ha, And),\n",
       " (Ow, Ow, Ow),\n",
       " (the, Knights, of),\n",
       " (one, this, one),\n",
       " (up, And, chickening),\n",
       " (buggering, up, And),\n",
       " (long, long, way),\n",
       " (out, bravely, taking),\n",
       " (you, your, son),\n",
       " (do, you, mean),\n",
       " (Aaaaaah, Aaaaaaaaah, woosh),\n",
       " (into, the, swamp),\n",
       " (of, two, young),\n",
       " (not, a, European),\n",
       " (for, your, dad),\n",
       " (do, It, like),\n",
       " (Sir, Launcelot, sir),\n",
       " (the, people, did),\n",
       " (handed, shall, make),\n",
       " (am, a, Knight),\n",
       " (all, over, him),\n",
       " (peril, do, think),\n",
       " (and, pray, understand),\n",
       " (hidden, Tim, Quite),\n",
       " (What, is, your),\n",
       " (thought, your, son),\n",
       " (stay, a, bit),\n",
       " (Spring, and, Summer),\n",
       " (Oh, quite, clear),\n",
       " (stood, up, to),\n",
       " (tell, your, master),\n",
       " (Well, you, have),\n",
       " (number, thou, shalt),\n",
       " (up, fire, without),\n",
       " (very, big, Well),\n",
       " (Arthur, Arthur, King),\n",
       " (the, middle, path),\n",
       " (Never, No, shrubberies),\n",
       " (not, tell, suffice),\n",
       " (count, and, the),\n",
       " (and, quiet, compared),\n",
       " (tree, in, the),\n",
       " (some, moistened, bint),\n",
       " (clang, Bring, out),\n",
       " (in, scene, twenty),\n",
       " (Three, Three, And),\n",
       " (He, going, to),\n",
       " (trusty, servant, Patsy),\n",
       " (Mind, your, own),\n",
       " (is, he, doing),\n",
       " (to, handsome, knights),\n",
       " (away, eh, You),\n",
       " (scenes, think, At),\n",
       " (in, thy, mercy),\n",
       " (she, got, a),\n",
       " (women, lying, in),\n",
       " (not, the, real),\n",
       " (off, Now, stand),\n",
       " (she, is, made),\n",
       " (English, pig, dogs),\n",
       " (clop, clop, rewr),\n",
       " (me, a, fortune),\n",
       " (Now, look, here),\n",
       " (knights, decided, that),\n",
       " (She, rich, She),\n",
       " (the, snows, of),\n",
       " (Well, simple, They),\n",
       " (slightly, higher, so),\n",
       " (Silly, little, bleeder),\n",
       " (shalt, thou, not),\n",
       " (a, moment, Oh),\n",
       " (Idiom, No, feel),\n",
       " (got, shit, all),\n",
       " (door, we, shall),\n",
       " (witch, witch, witch),\n",
       " (help, being, repressed),\n",
       " (lapin, de, bois),\n",
       " (lot, at, this),\n",
       " (got, a, rope),\n",
       " (Churches, Lead, Lead),\n",
       " (dark, forest, of),\n",
       " (Oooh, My, God),\n",
       " (go, to, the),\n",
       " (give, you, a),\n",
       " (she, turned, me),\n",
       " (not, a, witch),\n",
       " (quite, dead, sir),\n",
       " (ni, Nu, No),\n",
       " (had, worse, You),\n",
       " (could, not, carry),\n",
       " (Well, she, turned),\n",
       " (thou, take, out),\n",
       " (handle, this, lot),\n",
       " (If, you, do),\n",
       " (not, used, to),\n",
       " (nose, And, the),\n",
       " (makes, you, think),\n",
       " (Tim, Follow, But),\n",
       " (me, in, my),\n",
       " (out, of, your),\n",
       " (now, Well, now),\n",
       " (cruel, that, no),\n",
       " (against, my, will),\n",
       " (out, and, his),\n",
       " (felt, the, icy),\n",
       " (Look, that, rabbit),\n",
       " (Are, you, sure),\n",
       " (of, them, my),\n",
       " (do, want, any),\n",
       " (particular, sigh, Idiom),\n",
       " (your, door, opening),\n",
       " (Go, on, Bors),\n",
       " (Ni, Agh, Ni),\n",
       " (pass, through, this),\n",
       " (ere, the, other),\n",
       " (Is, it, Hurry),\n",
       " (velocity, a, swallow),\n",
       " (take, this, Aah),\n",
       " (Message, for, you),\n",
       " (get, a, glass),\n",
       " (sacred, castle, to),\n",
       " (have, Look, Just),\n",
       " (can, not, be),\n",
       " (to, you, no),\n",
       " (each, Well, awfully),\n",
       " (the, blood, of),\n",
       " (on, Concorde, thwonk),\n",
       " (perilous, Look, it),\n",
       " (pause, You, make),\n",
       " (want, We, want),\n",
       " (with, you, No),\n",
       " (it, again, That),\n",
       " (Let, him, handle),\n",
       " (Britons, My, liege),\n",
       " (now, averting, my),\n",
       " (have, died, in),\n",
       " (him, we, already),\n",
       " (Surely, you, not),\n",
       " (Yes, depart, a),\n",
       " (valor, for, the),\n",
       " (of, him, Sir),\n",
       " (But, many, times),\n",
       " (whether, she, is),\n",
       " (ponds, distributing, swords),\n",
       " (keep, him, in),\n",
       " (line, Well, simple),\n",
       " (Or, to, have),\n",
       " (And, you, Oh),\n",
       " (Ha, Now, you),\n",
       " (King, of, the),\n",
       " (us, easily, No),\n",
       " (of, that, Rather),\n",
       " (you, creep, No),\n",
       " (entering, the, room),\n",
       " (it, Oh, but),\n",
       " (became, convinced, that),\n",
       " (down, here, Oh),\n",
       " (a, fortune, Well),\n",
       " (do, want, any),\n",
       " (a, second, time),\n",
       " (weight, ratios, five),\n",
       " (No, Far, from),\n",
       " (the, Round, Table),\n",
       " (in, our, quest),\n",
       " (you, Thank, you),\n",
       " (the, very, living),\n",
       " (And, this, is),\n",
       " (and, the, glory),\n",
       " (so, foul, so),\n",
       " (back, of, the),\n",
       " (by, a, creature),\n",
       " (Ooh, said, it),\n",
       " (boom, pweeng, boom),\n",
       " (nice, And, how),\n",
       " (Bravely, ran, away),\n",
       " (Hic, Get, back),\n",
       " (nothing, yet, dappy),\n",
       " (Right, Oh, remember),\n",
       " (Aaaaugh, Stop, saying),\n",
       " (Oh, thank, you),\n",
       " (Haw, haw, heh),\n",
       " (court, at, Camelot),\n",
       " (that, Stop, that),\n",
       " (and, Uh, leap),\n",
       " (True, Uhh, Does),\n",
       " (cave, Tim, Follow),\n",
       " (hee, Ha, hee),\n",
       " (bonk, witch, witch),\n",
       " (thing, ca, stand),\n",
       " (changed, into, Spring),\n",
       " (as, can, No),\n",
       " (Say, Ni, Ni),\n",
       " (That, the, most),\n",
       " (ha, we, shall),\n",
       " (will, be, soon),\n",
       " (What, word, can),\n",
       " (forest, of, Ewing),\n",
       " (a, horse, Yes),\n",
       " (person, blow, my),\n",
       " (fled, No, singing),\n",
       " (are, nice, and),\n",
       " (penalty, Do, you),\n",
       " (nostrils, raped, and),\n",
       " (So, each, of),\n",
       " (handed, Yes, Let),\n",
       " (Hyy, Hya, Hiyya),\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with holy_grail\n",
    "set(ngrams(holy_grail, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Dispersion plots\n",
    "\n",
    "1. Load the `holy_grail.txt` dataset and create a dictionary of names and indexes like `{\"NAME\": [1, 2, 5, 10, ...]}` to store when does each proper noun appear among the 5 most frequent ones.\n",
    "2. Visualize the appearances of the character that is named the most.\n",
    "3. Visualize in the same graph the appearances of the top 5 characters to compare them.\n",
    "4. Do the same thing with the 5 most frequent names of `pride_prejudice.txt`.\n",
    "\n",
    "Something like:\n",
    "\n",
    "![Lexical dispersion plot](img/dispersion.png)\n",
    "\n",
    "or, alternatively:\n",
    "\n",
    "![Lexical dispersion alternative](img/dispersion2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fremont_bridge.csv  imdb.tsv   pythondevsurvey2017_raw_data.csv  titanic.csv\r\n",
      "goog.csv\t    model.txt  tabernas_meteo_data.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "holy_grail = nlp(open(\"data/holy_grail.txt\", 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "char_counter = Counter()\n",
    "\n",
    "for token in holy_grail:\n",
    "    if token.pos_ == 'PROPN':\n",
    "        char_counter[token.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARTHUR', 225),\n",
       " ('GALAHAD', 69),\n",
       " ('KNIGHT', 68),\n",
       " ('FATHER', 63),\n",
       " ('BEDEVERE', 61)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, _ = zip(*char_counter.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ARTHUR', 'GALAHAD', 'KNIGHT', 'FATHER', 'BEDEVERE')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = defaultdict(list)\n",
    "\n",
    "for token in holy_grail:\n",
    "    if token.text in names:\n",
    "        indexes[token.text].append(token.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff88df97780>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(5, sharex=True)\n",
    "\n",
    "for ii, name in enumerate(names):\n",
    "    axes[ii].eventplot(indexes[name], label=name, color=\"C{}\".format(ii))\n",
    "    axes[ii].get_yaxis().set_visible(False)\n",
    "\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BTS](img/Logo-BTS.jpg)\n",
    "\n",
    "# Session 19: Time Series Analysis (II)\n",
    "\n",
    "### Juan Luis Cano Rodr√≠guez <juan.cano@bts.tech> - Data Science Foundations (2018-12-11)\n",
    "\n",
    "Open this notebook in Google Colaboratory: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Juanlu001/bts-mbds-data-science-foundations/blob/master/sessions/18-Time-Series-Analysis-II.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: ARIMA forecast\n",
    "\n",
    "1. Read `data/air_passengers.csv` into a pandas **`Series`**, parsing the dates, indexing properly, and making sure there are no extraneous values (_Hint: Check the last rows_)\n",
    "2. Use statsmodels to decompose the seasonality of the series. Which model do you think it works best: `additive` or `multiplicative`?\n",
    "3. Use `statsmodels.graphics.tsaplots.plot_acf` to plot the autocorrelation function of the `seasonal` and `observed` components. Looking at the plots, what would you say it's the period of the seasonality?\n",
    "4. Save the first 70 % of points in a variable called `train`, and the remaining 30 % in `test`\n",
    "5. Use that seasonality period `m` as the only input to `pmdarima.arima.auto_arima` to automatically obtain a model and nothing else. What is the order?\n",
    "6. Save the model to a variable and use its `.predict` method to extract the prediction that overlaps with the test data, including the confidence intervals, and plot them. What happens? Is the model good?\n",
    "7. Use `model.resid()` to retrieve the residuals of the model and do a scatter plot to display their evolution in time\n",
    "8. Play with the parameters of `auto_arima` (don't raise them too much, and don't change the seasonality) to try to get a better result.\n",
    "\n",
    "![Forecast](img/sarimax.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Multiple seasonality experiments\n",
    "\n",
    "The Gas Demand dataset exhibits multiple seasonality, because we have _daily_ data that repeats over _weeks_ and _years_. Properly analyzing this is more difficult than \"just\" using an ARIMA model. **The objective is to do a forecast**.\n",
    "\n",
    "1. Read `data/gas_demand.csv` into a pandas **`DataFrame`** again, parsing the dates and indexing properly\n",
    "2. Split the dataset in 70 % of train and 30 % of test.\n",
    "3. Select a seasonality (for example `m=7`, the weekly pattern) and use `auto_arima` with that value to try to create a model that suits our dataset. What happens?\n",
    "4. Experiments:\n",
    "  * Keep only the last year month and create an `auto_arima` model.\n",
    "  * Extract the trend using a moving average (as we did in the previous class) and try to use it as an **exogenous** variable in `auto_arima`.\n",
    "  * Use a classical but non-ARIMA model, for example `statsmodels.tsa.holtwinters.ExponentialSmoothing`\n",
    "  * Use Prophet (from Facebook) to produce a good forecast.\n",
    "5. Plot the residuals of at least two of these models to compare them. Which one is better? Keep on experimenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

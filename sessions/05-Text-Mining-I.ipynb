{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BTS](img/Logo-BTS.jpg)\n",
    "\n",
    "# Session 5: Text Mining (I)\n",
    "\n",
    "### Juan Luis Cano Rodr√≠guez <juan.cano@bts.tech> - Data Science Foundations (2018-10-19)\n",
    "\n",
    "Open this notebook in Google Colaboratory: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Juanlu001/bts-mbds-data-science-foundations/blob/master/sessions/05-Text-Mining-I.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "![Pipeline](img/pipelines.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word and sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"This is a happy sentence by Michael O'Leary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'Some\\nspaces  and\\ttab characters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"In ancient Rome, some neighbors live in three adjacent houses. In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus. A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom. One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates). One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero. Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-speech tagging\n",
    "\n",
    "All tags recognized by spaCy are listed at https://spacy.io/api/annotation#pos-tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Information table\n",
    "\n",
    "Display a table with all the tokens of `text1` and the columns `[\"Text\", \"Lemma\", \"Coarse POS (pos)\", \"Fine POS (tag)\", \"Syntactic dependency\", \"Shape\", \"Alphanumeric\", \"Stop\"]`. Look in https://spacy.io/api/token#attributes for hints. Something like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Text</th>\n",
    "      <th>Lemma</th>\n",
    "      <th>Coarse POS (pos)</th>\n",
    "      <th>Fine POS (tag)</th>\n",
    "      <th>Syntactic dependency</th>\n",
    "      <th>Shape</th>\n",
    "      <th>Alphanumeric</th>\n",
    "      <th>Stop</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>This</td>\n",
    "      <td>this</td>\n",
    "      <td>DET</td>\n",
    "      <td>DT</td>\n",
    "      <td>nsubj</td>\n",
    "      <td>Xxxx</td>\n",
    "      <td>True</td>\n",
    "      <td>False</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>is</td>\n",
    "      <td>be</td>\n",
    "      <td>VERB</td>\n",
    "      <td>VBZ</td>\n",
    "      <td>ROOT</td>\n",
    "      <td>xx</td>\n",
    "      <td>True</td>\n",
    "      <td>True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>...</th>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity recognition\n",
    "\n",
    "https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = u'Apple is looking at buying U.K. startup for $1 billion'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabularies\n",
    "\n",
    "* `Vocab` objects contain a set of look-up tables that make common information available across documents.\n",
    "* Indexing the `Vocab` retrieves a `Lexeme`, which contains all the context-independent information about a word.\n",
    "\n",
    "![Vocabularies](img/vocab.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Word frequencies\n",
    "\n",
    "1. Load the `esa_news_all.parquet` dataset and display the 20 most frequent _lemmas_ that are not stopwords.\n",
    "2. Load the `holy_grail.txt` dataset and display the 5 most frequent proper nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: n-grams\n",
    "\n",
    "n-grams are sequences of n words that appear together.\n",
    "\n",
    "1. Load the `imdb.tsv` dataset and create a list of tokens that are not stopwords or uppercase (to remove the proper nouns).\n",
    "2. Compute a list of bigrams (2-grams) from this list. (Hint below)\n",
    "3. Write a function to produce the list of n-grams of any given text, where `n` is a parameter.\n",
    "4. Display the 10 most frequent 3-grams of `imdb.tsv` (you can reuse part of Exercise 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Dispersion plots\n",
    "\n",
    "1. Load the `holy_grail.txt` dataset and create a dictionary of names and indexes like `{\"NAME\": [1, 2, 5, 10, ...]}` to store when does each proper noun appear among the 5 most frequent ones.\n",
    "2. Visualize the appearances of the character that is named the most.\n",
    "3. Visualize in the same graph the appearances of the top 5 characters to compare them.\n",
    "4. Do the same thing with the 5 most frequent names of `pride_prejudice.txt`.\n",
    "\n",
    "Something like:\n",
    "\n",
    "![Lexical dispersion plot](img/dispersion.png)\n",
    "\n",
    "or, alternatively:\n",
    "\n",
    "![Lexical dispersion alternative](img/dispersion2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

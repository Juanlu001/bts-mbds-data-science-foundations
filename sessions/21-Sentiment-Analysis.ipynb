{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ![BTS](img/Logo-BTS.jpg)\n",
    "\n",
    "# Session 21: Sentiment Analysis\n",
    "\n",
    "### Juan Luis Cano Rodr√≠guez <juan.cano@bts.tech> - Data Science Foundations (2018-12-11)\n",
    "\n",
    "Open this notebook in Google Colaboratory: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Juanlu001/bts-mbds-data-science-foundations/blob/master/sessions/21-Sentiment-Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: scikit-learn helpers\n",
    "\n",
    "There are several libraries that provide higher level tools to evaluate and visualize scikit-learn models, for example:\n",
    "\n",
    "* https://github.com/reiinakano/scikit-plot\n",
    "* https://github.com/DistrictDataLabs/yellowbrick\n",
    "* https://github.com/rasbt/mlxtend\n",
    "\n",
    "Using the \"astrological method\" to rank popularity (that is, counting stars on GitHub) the top one is mlxtend. But using the \"provides way to plot confusion matrix **with class names** automatically\" metric, the best one is scikit-plot, which is the one we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Preprocessing\n",
    "\n",
    "1. Download the \"Large Movie Review Dataset\" from http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "2. Read all the text files from `aclImdb/train/pos/` and `aclImdb/train/neg/` into a pandas DataFrame called `train` with two columns: `review` (the text itself) and `sentiment` (`positive` or `negative`) (_Hint: Use the `glob` module_)\n",
    "\n",
    "<table class=\"dataframe\" border=\"1\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>review</th>\n",
    "      <th>sentiment</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>Today's sci-fi thrillers are more like Rambo i...</td>\n",
    "      <td>positive</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>I had the pleasure of seeing this film at the ...</td>\n",
    "      <td>positive</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>Deliriously romantic comedy with intertwining ...</td>\n",
    "      <td>positive</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>This movie is a fantastic movie. Everything ab...</td>\n",
    "      <td>positive</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>The documentary begins with setting the perspe...</td>\n",
    "      <td>positive</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "3. Do the same thing with `data_test`\n",
    "4. Create a `TfidfVectorizer` with:\n",
    "  * a _preprocessing_ step that removes the spurious `<br />` tags from the text,\n",
    "  * a _tokenizing_ step that uses Spacy to lemmatize the words, and\n",
    "  * its list of `stop_words` coming from Spacy\n",
    "\n",
    "(_Hint:_ https://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Single model\n",
    "\n",
    "1. Apply the `TfidfVectorizer` to the train data and fit a `LogisticRegression` model\n",
    "2. What is the accuracy?\n",
    "3. Use scikit-plot to plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Cross validation\n",
    "\n",
    "1. Concatenate `train` and `test` to produce `data`\n",
    "2. Use the `sklearn.cross_validation.cross_val_score` with 5 splits to produce a list of accuracy scores. Are they uniform?\n",
    "3. Use `scikitplot.estimators.plot_learning_curve` to plot the learning curves of our `LogisticRegression` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Model selection\n",
    "\n",
    "1. Use `GridSearchCV` to optimize the `C` hyperparameter of the `LogisticRegression`\n",
    "2. Try different classifiers (like a `RandomForestClassifier`), compute their accuracy, try optimizing their hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
